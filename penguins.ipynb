{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('penguins_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181</td>\n",
       "      <td>3750</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186</td>\n",
       "      <td>3800</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195</td>\n",
       "      <td>3250</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193</td>\n",
       "      <td>3450</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190</td>\n",
       "      <td>3650</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7                181   \n",
       "1  Adelie  Torgersen            39.5           17.4                186   \n",
       "2  Adelie  Torgersen            40.3           18.0                195   \n",
       "3  Adelie  Torgersen            36.7           19.3                193   \n",
       "4  Adelie  Torgersen            39.3           20.6                190   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0         3750    male  \n",
       "1         3800  female  \n",
       "2         3250  female  \n",
       "3         3450  female  \n",
       "4         3650    male  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            333 non-null    object \n",
      " 1   island             333 non-null    object \n",
      " 2   bill_length_mm     333 non-null    float64\n",
      " 3   bill_depth_mm      333 non-null    float64\n",
      " 4   flipper_length_mm  333 non-null    int64  \n",
      " 5   body_mass_g        333 non-null    int64  \n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 18.3+ KB\n"
     ]
    }
   ],
   "source": [
    "penguins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.992793</td>\n",
       "      <td>17.164865</td>\n",
       "      <td>200.966967</td>\n",
       "      <td>4207.057057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.468668</td>\n",
       "      <td>1.969235</td>\n",
       "      <td>14.015765</td>\n",
       "      <td>805.215802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>3550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.500000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.600000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.600000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>6300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "count      333.000000     333.000000         333.000000   333.000000\n",
       "mean        43.992793      17.164865         200.966967  4207.057057\n",
       "std          5.468668       1.969235          14.015765   805.215802\n",
       "min         32.100000      13.100000         172.000000  2700.000000\n",
       "25%         39.500000      15.600000         190.000000  3550.000000\n",
       "50%         44.500000      17.300000         197.000000  4050.000000\n",
       "75%         48.600000      18.700000         213.000000  4775.000000\n",
       "max         59.600000      21.500000         231.000000  6300.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species              0\n",
       "island               0\n",
       "bill_length_mm       0\n",
       "bill_depth_mm        0\n",
       "flipper_length_mm    0\n",
       "body_mass_g          0\n",
       "sex                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['species'] = penguins['species'].replace({'Adelie': 0, 'Gentoo': 1, 'Chinstrap': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Biscoe       163\n",
       "Dream        123\n",
       "Torgersen     47\n",
       "Name: island, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins['island'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "def encoder(df):\n",
    "    encoders = {}  # To store label encoders\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype == 'O':\n",
    "            lb = LabelEncoder()\n",
    "            df[i] = lb.fit_transform(df[i])\n",
    "            encoders[i] = lb  # Store the encoder\n",
    "    return df, encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins, encoders = encoder(penguins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181</td>\n",
       "      <td>3750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186</td>\n",
       "      <td>3800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195</td>\n",
       "      <td>3250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193</td>\n",
       "      <td>3450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190</td>\n",
       "      <td>3650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202</td>\n",
       "      <td>3400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193</td>\n",
       "      <td>3775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210</td>\n",
       "      <td>4100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198</td>\n",
       "      <td>3775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0          0       2            39.1           18.7                181   \n",
       "1          0       2            39.5           17.4                186   \n",
       "2          0       2            40.3           18.0                195   \n",
       "3          0       2            36.7           19.3                193   \n",
       "4          0       2            39.3           20.6                190   \n",
       "..       ...     ...             ...            ...                ...   \n",
       "328        2       1            55.8           19.8                207   \n",
       "329        2       1            43.5           18.1                202   \n",
       "330        2       1            49.6           18.2                193   \n",
       "331        2       1            50.8           19.0                210   \n",
       "332        2       1            50.2           18.7                198   \n",
       "\n",
       "     body_mass_g  sex  \n",
       "0           3750    1  \n",
       "1           3800    0  \n",
       "2           3250    0  \n",
       "3           3450    0  \n",
       "4           3650    1  \n",
       "..           ...  ...  \n",
       "328         4000    1  \n",
       "329         3400    0  \n",
       "330         3775    1  \n",
       "331         4100    1  \n",
       "332         3775    0  \n",
       "\n",
       "[333 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = penguins.drop('species', axis = 1)\n",
    "y = penguins['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181</td>\n",
       "      <td>3750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186</td>\n",
       "      <td>3800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195</td>\n",
       "      <td>3250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193</td>\n",
       "      <td>3450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190</td>\n",
       "      <td>3650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>207</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>202</td>\n",
       "      <td>3400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>49.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>193</td>\n",
       "      <td>3775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>50.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>210</td>\n",
       "      <td>4100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1</td>\n",
       "      <td>50.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>198</td>\n",
       "      <td>3775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0         2            39.1           18.7                181         3750   \n",
       "1         2            39.5           17.4                186         3800   \n",
       "2         2            40.3           18.0                195         3250   \n",
       "3         2            36.7           19.3                193         3450   \n",
       "4         2            39.3           20.6                190         3650   \n",
       "..      ...             ...            ...                ...          ...   \n",
       "328       1            55.8           19.8                207         4000   \n",
       "329       1            43.5           18.1                202         3400   \n",
       "330       1            49.6           18.2                193         3775   \n",
       "331       1            50.8           19.0                210         4100   \n",
       "332       1            50.2           18.7                198         3775   \n",
       "\n",
       "     sex  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  \n",
       "..   ...  \n",
       "328    1  \n",
       "329    0  \n",
       "330    1  \n",
       "331    1  \n",
       "332    0  \n",
       "\n",
       "[333 rows x 6 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "328    2\n",
       "329    2\n",
       "330    2\n",
       "331    2\n",
       "332    2\n",
       "Name: species, Length: 333, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>187</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>49.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>195</td>\n",
       "      <td>4400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1</td>\n",
       "      <td>52.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>205</td>\n",
       "      <td>4550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>185</td>\n",
       "      <td>3600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>47.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>222</td>\n",
       "      <td>5250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>216</td>\n",
       "      <td>4750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>37.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>184</td>\n",
       "      <td>3900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>39.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>193</td>\n",
       "      <td>3200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>45.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>198</td>\n",
       "      <td>3950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>181</td>\n",
       "      <td>3175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "22        0            40.5           17.9                187         3200   \n",
       "284       1            49.2           18.2                195         4400   \n",
       "294       1            52.8           20.0                205         4550   \n",
       "56        0            37.6           17.0                185         3600   \n",
       "175       0            47.3           15.3                222         5250   \n",
       "..      ...             ...            ...                ...          ...   \n",
       "188       0            49.6           15.0                216         4750   \n",
       "71        2            37.2           19.4                184         3900   \n",
       "106       0            39.7           17.7                193         3200   \n",
       "270       1            45.2           17.8                198         3950   \n",
       "102       0            38.1           17.0                181         3175   \n",
       "\n",
       "     sex  \n",
       "22     0  \n",
       "284    1  \n",
       "294    1  \n",
       "56     0  \n",
       "175    1  \n",
       "..   ...  \n",
       "188    1  \n",
       "71     1  \n",
       "106    0  \n",
       "270    0  \n",
       "102    0  \n",
       "\n",
       "[233 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label = y_train)\n",
    "dtest = xgb.DMatrix(x_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'max_depth': 3, 'eta': 0.1, 'objective': 'reg:squarederror', 'eval_metric': 'rmse'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:0.73967\n",
      "[1]\tTest-rmse:0.68107\n",
      "[2]\tTest-rmse:0.62997\n",
      "[3]\tTest-rmse:0.58642\n",
      "[4]\tTest-rmse:0.54798\n",
      "[5]\tTest-rmse:0.51708\n",
      "[6]\tTest-rmse:0.48924\n",
      "[7]\tTest-rmse:0.46767\n",
      "[8]\tTest-rmse:0.44796\n",
      "[9]\tTest-rmse:0.42846\n",
      "[10]\tTest-rmse:0.41112\n",
      "[11]\tTest-rmse:0.39846\n",
      "[12]\tTest-rmse:0.38619\n",
      "[13]\tTest-rmse:0.37614\n",
      "[14]\tTest-rmse:0.36798\n",
      "[15]\tTest-rmse:0.36222\n",
      "[16]\tTest-rmse:0.35673\n",
      "[17]\tTest-rmse:0.35145\n",
      "[18]\tTest-rmse:0.34721\n",
      "[19]\tTest-rmse:0.34219\n",
      "[20]\tTest-rmse:0.34068\n",
      "[21]\tTest-rmse:0.33975\n",
      "[22]\tTest-rmse:0.33929\n",
      "[23]\tTest-rmse:0.33921\n",
      "[24]\tTest-rmse:0.33943\n",
      "[25]\tTest-rmse:0.33638\n",
      "[26]\tTest-rmse:0.33620\n",
      "[27]\tTest-rmse:0.33692\n",
      "[28]\tTest-rmse:0.33738\n",
      "[29]\tTest-rmse:0.33830\n",
      "[30]\tTest-rmse:0.33942\n",
      "[31]\tTest-rmse:0.33924\n",
      "[32]\tTest-rmse:0.33910\n",
      "[33]\tTest-rmse:0.33902\n",
      "[34]\tTest-rmse:0.33773\n",
      "[35]\tTest-rmse:0.33738\n",
      "[36]\tTest-rmse:0.33710\n",
      "[37]\tTest-rmse:0.33690\n",
      "[38]\tTest-rmse:0.33675\n",
      "[39]\tTest-rmse:0.33664\n",
      "[40]\tTest-rmse:0.33657\n",
      "[41]\tTest-rmse:0.33650\n",
      "[42]\tTest-rmse:0.33644\n",
      "[43]\tTest-rmse:0.33642\n",
      "[44]\tTest-rmse:0.33631\n",
      "[45]\tTest-rmse:0.33638\n",
      "[46]\tTest-rmse:0.33640\n",
      "[47]\tTest-rmse:0.33639\n",
      "[48]\tTest-rmse:0.33632\n",
      "[49]\tTest-rmse:0.33631\n",
      "[50]\tTest-rmse:0.33627\n",
      "[51]\tTest-rmse:0.33625\n",
      "[52]\tTest-rmse:0.33645\n",
      "[53]\tTest-rmse:0.33645\n",
      "[54]\tTest-rmse:0.33645\n",
      "[55]\tTest-rmse:0.33645\n",
      "[56]\tTest-rmse:0.33643\n",
      "[57]\tTest-rmse:0.33647\n",
      "[58]\tTest-rmse:0.33645\n",
      "[59]\tTest-rmse:0.33644\n",
      "[60]\tTest-rmse:0.33645\n",
      "[61]\tTest-rmse:0.33647\n",
      "[62]\tTest-rmse:0.33647\n",
      "[63]\tTest-rmse:0.33649\n",
      "[64]\tTest-rmse:0.33654\n",
      "[65]\tTest-rmse:0.33654\n",
      "[66]\tTest-rmse:0.33648\n",
      "[67]\tTest-rmse:0.33641\n",
      "[68]\tTest-rmse:0.33644\n",
      "[69]\tTest-rmse:0.33643\n",
      "[70]\tTest-rmse:0.33646\n",
      "[71]\tTest-rmse:0.33641\n",
      "[72]\tTest-rmse:0.33644\n",
      "[73]\tTest-rmse:0.33644\n",
      "[74]\tTest-rmse:0.33644\n",
      "[75]\tTest-rmse:0.33505\n",
      "[76]\tTest-rmse:0.33506\n",
      "[77]\tTest-rmse:0.33489\n",
      "[78]\tTest-rmse:0.33459\n",
      "[79]\tTest-rmse:0.33335\n",
      "[80]\tTest-rmse:0.33335\n",
      "[81]\tTest-rmse:0.33333\n",
      "[82]\tTest-rmse:0.33308\n",
      "[83]\tTest-rmse:0.33309\n",
      "[84]\tTest-rmse:0.33272\n",
      "[85]\tTest-rmse:0.33272\n",
      "[86]\tTest-rmse:0.33268\n",
      "[87]\tTest-rmse:0.33266\n",
      "[88]\tTest-rmse:0.33261\n",
      "[89]\tTest-rmse:0.33259\n",
      "[90]\tTest-rmse:0.33263\n",
      "[91]\tTest-rmse:0.33262\n",
      "[92]\tTest-rmse:0.33264\n",
      "[93]\tTest-rmse:0.33266\n",
      "[94]\tTest-rmse:0.33266\n",
      "[95]\tTest-rmse:0.33263\n",
      "[96]\tTest-rmse:0.33263\n",
      "[97]\tTest-rmse:0.33269\n",
      "[98]\tTest-rmse:0.33268\n",
      "[99]\tTest-rmse:0.33270\n"
     ]
    }
   ],
   "source": [
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds, evals = [(dtest, 'Test')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.00863455e-02,  2.01083279e+00, -1.50815621e-01,  1.00082755e+00,\n",
       "       -2.26033339e-03,  1.95919240e+00,  2.01121020e+00,  1.00082755e+00,\n",
       "        1.00520957e+00,  1.00199664e+00,  2.57579446e-01,  5.52903581e-03,\n",
       "        8.74693036e-01,  6.32853247e-03,  2.01226640e+00,  1.32485293e-02,\n",
       "        3.29945306e-03,  1.00193179e+00,  3.61338165e-03,  2.01226640e+00,\n",
       "        6.27781093e-01,  1.02434587e-02,  2.01679301e+00,  1.00082755e+00,\n",
       "        4.89980355e-02,  4.88264970e-02,  1.00082755e+00,  2.01819468e+00,\n",
       "        1.03840828e+00,  2.01501656e+00,  1.00193179e+00,  2.01396370e+00,\n",
       "       -1.66163087e-01,  1.06480578e-02,  2.02832603e+00,  2.00536609e+00,\n",
       "        6.39255047e-02,  1.00520957e+00,  5.27248267e-05,  3.29945306e-03,\n",
       "        3.94517519e-02,  9.31997411e-03,  1.00082755e+00,  9.78396773e-01,\n",
       "       -5.33755776e-03,  5.93768805e-03,  2.00745583e+00, -9.31908656e-03,\n",
       "       -2.53910180e-02,  1.86939836e+00,  5.27248267e-05,  4.24100786e-01,\n",
       "        9.99921560e-01,  6.23535411e-03, -1.49775548e-02,  1.00082755e+00,\n",
       "        8.06735829e-03, -5.68555109e-02,  1.00520957e+00,  1.00082755e+00,\n",
       "        8.72272193e-01,  2.00882864e+00,  2.01114702e+00, -5.71710989e-03,\n",
       "       -9.92740877e-03,  2.02781796e+00,  1.34303980e-03,  1.00385022e+00,\n",
       "        6.68174122e-03,  2.05570534e-02, -1.41715622e-02, -1.52678546e-02,\n",
       "        1.00847137e+00,  2.00427818e+00,  5.99677682e-01,  9.93440688e-01,\n",
       "       -1.59512553e-02, -1.19420085e-02,  7.06059858e-04,  1.00520957e+00,\n",
       "       -1.03839226e-02, -2.97739590e-03,  9.82537806e-01,  7.43607245e-03,\n",
       "        2.02997231e+00,  1.00847137e+00, -1.73563454e-02,  2.00708461e+00,\n",
       "        1.11610293e+00,  1.00089240e+00,  1.00082755e+00,  2.02026391e+00,\n",
       "        4.65155439e-03, -2.95233913e-03, -5.98525628e-03,  3.29744280e-03,\n",
       "       -6.58955425e-02,  1.00199664e+00,  1.63514829e+00, -2.16928553e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.332697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 6)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost has been fitted.\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.98, Precision: 0.98, Recall: 0.98, F1 Score: 0.98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:15:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"eval_metrics\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model saved to saved_models\\XGBoost.pkl\n"
     ]
    }
   ],
   "source": [
    "class models:\n",
    "    def __init__(self, data, target, encoders):\n",
    "        self.encoders = encoders\n",
    "        x = data.drop(target, axis = 1)\n",
    "        y = data[target]\n",
    "\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "        self.models = {\n",
    "            'XGBoost': xgb.XGBClassifier(use_label_encoder = False, eval_metrics = 'logloss')\n",
    "        }\n",
    "\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def fit_models(self):\n",
    "        for name, model in self.models.items():\n",
    "            model.fit(self.x_train, self.y_train)\n",
    "            print(f'{name} has been fitted.')\n",
    "\n",
    "    def evaluate_models(self):\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            predictions = model.predict(self.x_test)\n",
    "            accuracy = accuracy_score(self.y_test, predictions)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(self.y_test, predictions, average='weighted')\n",
    "            report = classification_report(self.y_test, predictions)\n",
    "\n",
    "            self.metrics[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "            print(f'{name} Metrics:')\n",
    "            print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\\n')\n",
    "\n",
    "    def visualize_comparision(self):\n",
    "\n",
    "        metrics_df = pd.DataFrame(self.metrics)\n",
    "        for metric in metrics_df.columns:\n",
    "            sns.barplot(x = metrics_df.index, y = metrics_df[metric])\n",
    "            plt.title(f'Comparison of {metric}')\n",
    "            plt.ylabel(metric)\n",
    "            plt.show()\n",
    "\n",
    "    def save_model(self, directory='saved_models'):\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Save models\n",
    "        for name, model in self.models.items():\n",
    "            filename = os.path.join(directory, f'{name}.pkl')\n",
    "            with open(filename, 'wb') as file:\n",
    "                pickle.dump(model, file)\n",
    "            print(f'{name} model saved to {filename}')\n",
    "\n",
    "        # Save Label Encoders\n",
    "        for col, lb in self.encoders.items():  # Change here\n",
    "            joblib.dump(lb, os.path.join(directory, f'{col}_encoder.pkl'))\n",
    "\n",
    "\n",
    "model = models(penguins, 'species', encoders)\n",
    "model.fit_models()\n",
    "model.evaluate_models()\n",
    "model.visualize_comparision()\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 68.1761 - accuracy: 0.3133\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 21.0522 - accuracy: 0.3991\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 10.6648 - accuracy: 0.3133\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 7.5739 - accuracy: 0.2275\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 9.2351 - accuracy: 0.3433\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 11.3362 - accuracy: 0.3691\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 13.0293 - accuracy: 0.3391\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.7207 - accuracy: 0.3348\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.9941 - accuracy: 0.3433\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.0709 - accuracy: 0.2961\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.9530 - accuracy: 0.3906\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.6825 - accuracy: 0.4077\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.6197 - accuracy: 0.2918\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 7.4261 - accuracy: 0.3176\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 3.5566 - accuracy: 0.2961\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.1124 - accuracy: 0.3391\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.7200 - accuracy: 0.4592\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.7387 - accuracy: 0.4163\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.2170 - accuracy: 0.4335\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3932 - accuracy: 0.4506\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.6471 - accuracy: 0.3262\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 9.9121 - accuracy: 0.2961\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.4705 - accuracy: 0.4592\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.8329 - accuracy: 0.3863\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.3582 - accuracy: 0.3605\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9106 - accuracy: 0.4034\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.1029 - accuracy: 0.3691\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.4642 - accuracy: 0.3948\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.2395 - accuracy: 0.3863\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.8789 - accuracy: 0.5021\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.0526 - accuracy: 0.4421\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.9468 - accuracy: 0.5365\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5133 - accuracy: 0.4764\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3621 - accuracy: 0.5150\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.7875 - accuracy: 0.4120\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8006 - accuracy: 0.6094\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.2500 - accuracy: 0.4206\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.6611 - accuracy: 0.5494\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.7516 - accuracy: 0.4893\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.9058 - accuracy: 0.5021\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4.3720 - accuracy: 0.4163\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.2885 - accuracy: 0.5536\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.2066 - accuracy: 0.5279\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.7339 - accuracy: 0.5150\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3950 - accuracy: 0.5536\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2959 - accuracy: 0.6180\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2870 - accuracy: 0.6137\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0416 - accuracy: 0.6009\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0197 - accuracy: 0.6352\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0312 - accuracy: 0.5966\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7702 - accuracy: 0.6695\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7638 - accuracy: 0.7082\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8354 - accuracy: 0.6910\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8232 - accuracy: 0.6652\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1050 - accuracy: 0.5665\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9562 - accuracy: 0.6309\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9667 - accuracy: 0.6567\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9881 - accuracy: 0.6223\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8962 - accuracy: 0.6824\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2616 - accuracy: 0.5579\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4528 - accuracy: 0.5794\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4326 - accuracy: 0.5923\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5071 - accuracy: 0.6052\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8813 - accuracy: 0.6438\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0882 - accuracy: 0.5966\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4262 - accuracy: 0.5751\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7713 - accuracy: 0.6609\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5270 - accuracy: 0.5150\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.2569 - accuracy: 0.5150\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.2006 - accuracy: 0.5622\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.4632 - accuracy: 0.5107\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.9298 - accuracy: 0.5536\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.4184 - accuracy: 0.6738\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.6317 - accuracy: 0.6352\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.1950 - accuracy: 0.5150\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 6.0168 - accuracy: 0.3648\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.6135 - accuracy: 0.5064\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.3272 - accuracy: 0.4077\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 4.4269 - accuracy: 0.5665\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.0896 - accuracy: 0.4464\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3803 - accuracy: 0.6266\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0620 - accuracy: 0.6652\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.6824\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9939 - accuracy: 0.6609\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0760 - accuracy: 0.6395\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9758 - accuracy: 0.6781\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1555 - accuracy: 0.6567\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9459 - accuracy: 0.6867\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1269 - accuracy: 0.6395\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8704 - accuracy: 0.7039\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6612 - accuracy: 0.6137\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.6689 - accuracy: 0.5751\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9271 - accuracy: 0.6695\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8405 - accuracy: 0.6867\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.4829 - accuracy: 0.5665\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.3865 - accuracy: 0.5622\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8246 - accuracy: 0.5708\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8001 - accuracy: 0.5536\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.0909 - accuracy: 0.5408\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2190 - accuracy: 0.6567\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8660 - accuracy: 0.6609\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1364 - accuracy: 0.6180\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3538 - accuracy: 0.6009\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.5873 - accuracy: 0.5408\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1864 - accuracy: 0.6438\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7511\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.8069\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.7597\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7940\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7511\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8943 - accuracy: 0.7253\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8561 - accuracy: 0.6738\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3786 - accuracy: 0.5880\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7698 - accuracy: 0.7039\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6265 - accuracy: 0.7296\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4332 - accuracy: 0.5751\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0440 - accuracy: 0.6867\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7511\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.7468\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7907 - accuracy: 0.7296\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7684 - accuracy: 0.7296\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3468 - accuracy: 0.6524\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5111 - accuracy: 0.6738\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6737 - accuracy: 0.6052\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.0548 - accuracy: 0.6137\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.6996\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.6824\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7253\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5553 - accuracy: 0.5923\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4072 - accuracy: 0.5794\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.3734 - accuracy: 0.5322\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.6271 - accuracy: 0.5665\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.0688 - accuracy: 0.6137\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3244 - accuracy: 0.6395\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7382\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.6781\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.7210\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.1534 - accuracy: 0.5365\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.7116 - accuracy: 0.5494\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8571 - accuracy: 0.7167\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7082\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3482 - accuracy: 0.6395\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.6609\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.3880 - accuracy: 0.5236\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.0905 - accuracy: 0.5837\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.9909 - accuracy: 0.5536\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.5993 - accuracy: 0.6738\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.8608 - accuracy: 0.6609\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.0958 - accuracy: 0.5365\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8463 - accuracy: 0.6309\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7691 - accuracy: 0.6867\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.7210\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 8.7095 - accuracy: 0.4249\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.7495 - accuracy: 0.4635\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 4.6071 - accuracy: 0.3991\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.5919 - accuracy: 0.4163\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 6.5883 - accuracy: 0.4807\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 5.1538 - accuracy: 0.4979\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1986 - accuracy: 0.6524\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8709 - accuracy: 0.7167\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9697 - accuracy: 0.6781\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.5006 - accuracy: 0.5579\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3986 - accuracy: 0.5837\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1328 - accuracy: 0.6609\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4147 - accuracy: 0.6781\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9308 - accuracy: 0.7082\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5732 - accuracy: 0.6781\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5472 - accuracy: 0.7082\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7425\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7983\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.7940\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8455\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8412\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8434 - accuracy: 0.7253\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.7296\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7639\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8755\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8841\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8455\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8069\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.9056\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8155\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8755\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8069\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8755\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8026\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8884\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7725\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.7425\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8283\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7854\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9778 - accuracy: 0.6352\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5004 - accuracy: 0.6223\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 2.5299 - accuracy: 0.5837\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.7854\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.4427 - accuracy: 0.8412\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.7253\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.7296\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.8155\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.7897\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7639\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8970\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.9013\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8026\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7983\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.7296\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8541\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.0261 - accuracy: 0.7039\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8786 - accuracy: 0.7253\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8137 - accuracy: 0.6996\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7253\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.7940\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8584\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4843 - accuracy: 0.5966\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.7632 - accuracy: 0.5708\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.7545 - accuracy: 0.5751\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.1973 - accuracy: 0.4807\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3695 - accuracy: 0.6738\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6420 - accuracy: 0.7339\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.9227\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8026\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8069\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.9227\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8369\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.7382\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.7382\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.2311 - accuracy: 0.6052\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4.2891 - accuracy: 0.4034\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.8220 - accuracy: 0.5837\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.8925 - accuracy: 0.6266\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4931 - accuracy: 0.6223\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.5502 - accuracy: 0.6652\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9264 - accuracy: 0.7124\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.8155\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8670\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.9399\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.8369\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9356\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9399\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8541\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8498\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.9227\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8755\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.7768\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.9142\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.9013\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8369\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7725\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8317 - accuracy: 0.6524\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5217 - accuracy: 0.6309\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0960 - accuracy: 0.7682\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2168 - accuracy: 0.6738\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2622 - accuracy: 0.6567\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5256 - accuracy: 0.6137\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4802 - accuracy: 0.7167\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9918 - accuracy: 0.7296\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.6829 - accuracy: 0.5837\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4.2397 - accuracy: 0.5193\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.7632 - accuracy: 0.4850\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.8543 - accuracy: 0.6524\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4434 - accuracy: 0.6524\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1013 - accuracy: 0.6609\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8412\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.9142\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.8670\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8412\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.8841\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8670\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9142\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9270\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.9142\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.8884\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8670\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8240\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8197\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8712\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9485\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9528\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9013\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7597\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7768\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4258 - accuracy: 0.6481\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.7082\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.7725\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8455\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8197\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.7768\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7884 - accuracy: 0.5494\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4.2966 - accuracy: 0.5150\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.1645 - accuracy: 0.5579\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4200 - accuracy: 0.6309\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.7725\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8314 - accuracy: 0.7210\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0662 - accuracy: 0.7167\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7940\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9270\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8498\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9270\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8712\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8155\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8627\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2813 - accuracy: 0.8584\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8584\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8283\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8069\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.9142\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9313\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8712\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8798\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.9700\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9227\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9313\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9356\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.8798\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8605 - accuracy: 0.6996\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6320 - accuracy: 0.6695\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3601 - accuracy: 0.7124\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.7639\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8340 - accuracy: 0.7296\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.0514 - accuracy: 0.5665\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1279 - accuracy: 0.7382\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7682\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.7725\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8369\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8369\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.9485\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8155\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0226 - accuracy: 0.6953\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3102 - accuracy: 0.7253\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8267 - accuracy: 0.7511\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.7124\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2684 - accuracy: 0.7425\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0062 - accuracy: 0.6781\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.7940\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8283\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.7811\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8204 - accuracy: 0.7210\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8627\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8627\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8884\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9270\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.9442\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8927\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9013\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.8927\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9442\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.8026\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8283\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9185\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9571\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8970\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8412\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2568 - accuracy: 0.8798\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8970\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8627\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9313\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2718 - accuracy: 0.8927\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8455\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.8283\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 0.8884\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8455\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2754 - accuracy: 0.8798\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8197\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8584\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7725\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8584\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8112\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.7854\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9700\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9657\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9485\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.8798\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9657\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8584\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8498\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7725\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8326\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1320 - accuracy: 0.6996\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0956 - accuracy: 0.6867\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8369\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7897\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.7296\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.8841\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.9227\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.8026\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.7554\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2650 - accuracy: 0.6910\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.7339\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8627\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9056\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9571\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1395 - accuracy: 0.9571\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9185\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.8927\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9227\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.8712\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8026\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8541\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7811\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.8069\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7811\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.8069\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.8841\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8670\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.8026\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7811\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7682\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7781 - accuracy: 0.7039\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9275 - accuracy: 0.7554\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7809 - accuracy: 0.6824\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9028 - accuracy: 0.7082\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8155\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9442\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.8069\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7897\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8498\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8755\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9614\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9313\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9313\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9399\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.8927\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9185\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8627\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.8026\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.8841\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9571\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.8498\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7725\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.7768\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8841\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.8841\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.8026\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0171 - accuracy: 0.7597\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0111 - accuracy: 0.6996\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9185\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8670\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7854\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.7854\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.1894 - accuracy: 0.9056\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9442\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9700\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8627\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9056\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8712\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8884\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9442\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9485\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9227\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.9270\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9700\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8927\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9013\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9614\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9657\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9785\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9614\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9356\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9485\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8498\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8970\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.9185\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8755\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8670\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9142\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9657\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9227\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9528\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9356\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9571\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8627\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9142\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9785\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9399\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9742\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9785\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9614\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9528\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9742\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9657\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8755\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1480 - accuracy: 0.7124\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.1832 - accuracy: 0.7210\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9099\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7682\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2313 - accuracy: 0.8884\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9013\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9356\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9657\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9227\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9528\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9485\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9528\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9313\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8326\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2294 - accuracy: 0.9227\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9657\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9700\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9185\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9485\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.7854\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.8970\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9785\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9485\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9442\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9399\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.7768\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.8155\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.8026\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.7682\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8744 - accuracy: 0.7854\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.7167\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7236 - accuracy: 0.8069\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.8283\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9227\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.8112\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8069\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.4230 - accuracy: 0.8155\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.4532 - accuracy: 0.8283\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8584\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5223 - accuracy: 0.6910\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.6366 - accuracy: 0.7854\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.8026\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8986 - accuracy: 0.7811\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7639\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7889 - accuracy: 0.7725\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.8584\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8670\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8798\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8498\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9442\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9185\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9657\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9571\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9871\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.9700\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9270\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8412\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.8884\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9013\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9313\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.9871\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9356\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2205 - accuracy: 0.9013\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.9185\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9356\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9742\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9914\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9399\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9571\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.9270\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8884\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1655 - accuracy: 0.9270\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9185\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.9185\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9399\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9571\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8670\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.9013\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9528\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8712\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.8884\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8541\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9123 - accuracy: 0.7296\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.8240\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8326\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9099\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9485\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8927\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8712\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6153 - accuracy: 0.7854\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.4285 - accuracy: 0.4635\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 4.2929 - accuracy: 0.6695\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.1788 - accuracy: 0.7682\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.5680 - accuracy: 0.6738\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.7597\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9700\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9571\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9657\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1708 - accuracy: 0.9313\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9399\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9142\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9399\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9227\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9785\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9785\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9270\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9185\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9313\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9657\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9399\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9399\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9828\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9013\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8884\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8755\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7854\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.8970\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2786 - accuracy: 0.8712\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8584\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8498\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9270\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9485\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9528\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.8412\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.8240\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8755\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9142\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7771 - accuracy: 0.7468\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8455\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9828\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8755\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.7983\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.7639\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.7897\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8400 - accuracy: 0.7725\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8584\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9056\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9142\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9571\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9657\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.8927\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9313\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9614\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9657\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9700\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9785\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9785\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9742\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9270\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9142\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.8197\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.3824 - accuracy: 0.6910\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9280 - accuracy: 0.8069\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8455\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9056\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9270\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2791 - accuracy: 0.8927\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8712\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8755\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9571\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9528\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9185\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9742\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9485\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9442\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8884\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.9056\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8627\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9399\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9356\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9185\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8884\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9313\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9485\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9871\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9399\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9657\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9399\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8670\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9485\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9571\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9442\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9485\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9185\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9528\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9485\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9742\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9742\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.8970\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9313\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.9399\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9571\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9742\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9614\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9485\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9914\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9785\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9571\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9742\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9828\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9871\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9871\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9785\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0882 - accuracy: 0.9657\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9142\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7275 - accuracy: 0.6567\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.4633 - accuracy: 0.5837\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.2545 - accuracy: 0.6094\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7363 - accuracy: 0.7253\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.8155\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.8441 - accuracy: 0.6180\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.9496 - accuracy: 0.4807\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.5355 - accuracy: 0.6652\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.6041 - accuracy: 0.6395\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2072 - accuracy: 0.7468\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7857 - accuracy: 0.6910\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2.6884 - accuracy: 0.5923\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3.1540 - accuracy: 0.5451\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.6575 - accuracy: 0.7167\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.7682\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9056\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.9356\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9185\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1085 - accuracy: 0.9700\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9700\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9571\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9785\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9742\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9742\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1635 - accuracy: 0.9270\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9871\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9871\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9742\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9785\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9828\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9742\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9785\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9742\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1128 - accuracy: 0.9700\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9571\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1717 - accuracy: 0.9442\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1313 - accuracy: 0.9571\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9657\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9270\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1001 - accuracy: 0.9742\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9742\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9914\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.9871\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9700\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9657\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9742\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9914\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9700\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9742\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9785\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9871\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9614\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9614\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9742\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9700\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9700\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9785\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9828\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0674 - accuracy: 0.9871\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9914\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9485\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0732 - accuracy: 0.9914\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9828\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9742\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 998us/step - loss: 0.1552 - accuracy: 0.9528\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.2206 - accuracy: 0.9099\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9571\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9828\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9871\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.9742\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9742\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9700\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9399\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9700\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9871\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9914\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0996 - accuracy: 0.9657\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1236 - accuracy: 0.9528\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9700\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0706 - accuracy: 0.9914\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.9313\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9442\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9957\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0690 - accuracy: 0.9871\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9828\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9313\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1654 - accuracy: 0.9227\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9142\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0963 - accuracy: 0.9614\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9657\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1213 - accuracy: 0.9657\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.0793 - accuracy: 0.9785\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9742\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9871\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9657\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9399\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9356\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9785\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9742\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1147 - accuracy: 0.9657\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9442\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9185\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8584\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9528\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9399\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9013\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.9013\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9227\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9657\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9785\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9742\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9399\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8927\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9442\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9313\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9227\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8670\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9785\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9571\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9871\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9871\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9785\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9528\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9957\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9356\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9700\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9871\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9785\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9828\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9742\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9742\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9657\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9785\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9742\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.9313\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9871\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9700\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9442\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9270\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9742\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.8112\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4165 - accuracy: 0.6738\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9528\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9614\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9657\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9785\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9528\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9871\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9742\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9742\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9828\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9742\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9571\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9828\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9785\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9828\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9485\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9571\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9785\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9614\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8755\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.9013\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.8240\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8627\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.8798\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.8069\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.9013\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9270\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.8884\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9227\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.8798\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7639\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.9142\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.7854\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8884\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.9399\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9700\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9700\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.9442\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9270\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.8927\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9914\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9700\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9828\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9785\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9785\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9742\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9700\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9356\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.9270\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9657\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9785\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9657\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9485\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9399\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8541\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9485\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9399\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9571\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9614\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9957\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9485\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9828\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9785\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9442\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9700\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9914\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9828\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9828\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9742\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9785\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9742\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9571\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.9313\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9742\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9914\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9528\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9313\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8670\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8903 - accuracy: 0.6781\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9456 - accuracy: 0.7339\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.8179 - accuracy: 0.6867\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.0008 - accuracy: 0.6953\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.7171 - accuracy: 0.6309\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8902 - accuracy: 0.7339\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.7296\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7811\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8197\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.9142\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6824\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7193 - accuracy: 0.7210\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7639\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8283\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8798\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.9442\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.8970\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7983\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8197\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8369\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.8155\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8369\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9303 - accuracy: 0.6738\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.7124\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7425\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8498\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9270\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9614\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9528\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.9356\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.9056\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9013\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8927\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8498\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9056\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9614\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.9700\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9485\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9356\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9313\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9485\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9528\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9399\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9099\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9785\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8283\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.8884\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8884\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9700\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9614\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1282 - accuracy: 0.9828\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.8712\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8584\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9571\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9227\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8283\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9485\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.9356\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9227\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1832 - accuracy: 0.9356\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9485\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1933 - accuracy: 0.9313\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1878 - accuracy: 0.9399\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9270\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1828 - accuracy: 0.9270\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.9013\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9313\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9700\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 997us/step - loss: 0.1077 - accuracy: 0.9785\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9828\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9828\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9742\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9785\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9185\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9442\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9614\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9528\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9056\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9780 - accuracy: 0.6953\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8614 - accuracy: 0.7468\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8455\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8970\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.9056\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9528\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2160 - accuracy: 0.9142\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.9313\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8627\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.9013\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9528\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9871\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9485\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9356\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9700\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9742\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9442\n",
      "NeuralNetwork has been fitted.\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9300\n",
      "[0.17581769824028015, 0.9300000071525574]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class ann:\n",
    "    def __init__(self, data, target, input_shape):\n",
    "        x = data.drop(target, axis=1)\n",
    "        y = data[target]\n",
    "\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.model = {\n",
    "            'NeuralNetwork': keras.Sequential([\n",
    "                layers.Dense(128, activation='relu', input_shape=(self.input_shape,)),\n",
    "                layers.Dense(64, activation='relu'),\n",
    "                layers.Dense(32, activation='relu'),\n",
    "                layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
    "            ]),\n",
    "        }\n",
    "\n",
    "        self.metrics = {}\n",
    "\n",
    "    def compile_neural_network(self):\n",
    "        if 'NeuralNetwork' in self.model:\n",
    "            self.model['NeuralNetwork'].compile(optimizer='adam', \n",
    "                                                loss='sparse_categorical_crossentropy',  # Adjust based on y format\n",
    "                                                metrics=['accuracy'])\n",
    "\n",
    "    def fit_models(self):\n",
    "        for name, model in self.model.items():\n",
    "            model.fit(self.x_train, self.y_train, epochs=1000)  # Adjust epochs as necessary\n",
    "            print(f'{name} has been fitted.')\n",
    "\n",
    "    def evaluate_models(self):\n",
    "        for name, model in self.model.items():\n",
    "            predictions = model.predict(self.x_test)\n",
    "            predictions = predictions.argmax(axis=1)  # Converting probabilities to class indices\n",
    "            \n",
    "            result = model.evaluate(self.x_test, self.y_test)\n",
    "\n",
    "            print(f'{result}')\n",
    "\n",
    "\n",
    "model = ann(penguins, 'species', 6)\n",
    "model.compile_neural_network()\n",
    "model.fit_models()\n",
    "model.evaluate_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the above Artificial Neural Network\n",
    "\n",
    "Let's do some optimization by adding drop-out layers, early stop policy, incorporate the l2 regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 1s 37ms/step - loss: 1.2944 - accuracy: 0.3387 - val_loss: 1.1750 - val_accuracy: 0.5957\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1836 - accuracy: 0.4892 - val_loss: 1.0775 - val_accuracy: 0.8298\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0807 - accuracy: 0.5968 - val_loss: 0.9873 - val_accuracy: 0.8085\n",
      "Epoch 4/1000\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0952 - accuracy: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0284 - accuracy: 0.6344 - val_loss: 0.8904 - val_accuracy: 0.8085\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9974 - accuracy: 0.6452 - val_loss: 0.7946 - val_accuracy: 0.8085\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8591 - accuracy: 0.7366 - val_loss: 0.7035 - val_accuracy: 0.8085\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8445 - accuracy: 0.7581 - val_loss: 0.6213 - val_accuracy: 0.8298\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7504 - accuracy: 0.7634 - val_loss: 0.5481 - val_accuracy: 0.8298\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.7742 - val_loss: 0.4896 - val_accuracy: 0.8298\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6168 - accuracy: 0.8065 - val_loss: 0.4443 - val_accuracy: 0.8298\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5785 - accuracy: 0.8495 - val_loss: 0.4110 - val_accuracy: 0.8511\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5419 - accuracy: 0.8280 - val_loss: 0.3874 - val_accuracy: 0.8511\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5409 - accuracy: 0.8172 - val_loss: 0.3667 - val_accuracy: 0.8723\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4970 - accuracy: 0.8548 - val_loss: 0.3474 - val_accuracy: 0.8936\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4724 - accuracy: 0.8656 - val_loss: 0.3285 - val_accuracy: 0.9149\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4218 - accuracy: 0.8978 - val_loss: 0.3084 - val_accuracy: 0.9574\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4411 - accuracy: 0.8871 - val_loss: 0.2867 - val_accuracy: 0.9787\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.9194 - val_loss: 0.2671 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3869 - accuracy: 0.9194 - val_loss: 0.2489 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3249 - accuracy: 0.9355 - val_loss: 0.2310 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3613 - accuracy: 0.9032 - val_loss: 0.2129 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3232 - accuracy: 0.9409 - val_loss: 0.2001 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2872 - accuracy: 0.9570 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2589 - accuracy: 0.9785 - val_loss: 0.1775 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2682 - accuracy: 0.9785 - val_loss: 0.1682 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2646 - accuracy: 0.9516 - val_loss: 0.1613 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2415 - accuracy: 0.9731 - val_loss: 0.1565 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2215 - accuracy: 0.9785 - val_loss: 0.1527 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2101 - accuracy: 0.9785 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2624 - accuracy: 0.9677 - val_loss: 0.1464 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2014 - accuracy: 0.9785 - val_loss: 0.1439 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1878 - accuracy: 0.9839 - val_loss: 0.1414 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1846 - accuracy: 0.9946 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2182 - accuracy: 0.9785 - val_loss: 0.1370 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2371 - accuracy: 0.9677 - val_loss: 0.1355 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1751 - accuracy: 0.9946 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1823 - accuracy: 0.9839 - val_loss: 0.1339 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 0.9946 - val_loss: 0.1329 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1590 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1954 - accuracy: 0.9839 - val_loss: 0.1304 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1736 - accuracy: 0.9892 - val_loss: 0.1291 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1742 - accuracy: 0.9892 - val_loss: 0.1282 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1602 - accuracy: 0.9892 - val_loss: 0.1272 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1611 - accuracy: 0.9892 - val_loss: 0.1262 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1745 - accuracy: 0.9892 - val_loss: 0.1245 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1517 - accuracy: 0.9892 - val_loss: 0.1239 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1602 - accuracy: 0.9946 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1506 - accuracy: 0.9946 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1979 - accuracy: 0.9785 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1666 - accuracy: 0.9839 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1643 - accuracy: 0.9892 - val_loss: 0.1200 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1613 - accuracy: 0.9839 - val_loss: 0.1192 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 0.9839 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1659 - accuracy: 0.9839 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.9839 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1849 - accuracy: 0.9892 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1645 - accuracy: 0.9946 - val_loss: 0.1160 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1631 - accuracy: 0.9839 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1757 - accuracy: 0.9946 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1588 - accuracy: 0.9785 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1413 - accuracy: 0.9946 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1442 - accuracy: 0.9946 - val_loss: 0.1124 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1296 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1400 - accuracy: 0.9839 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1391 - accuracy: 0.9946 - val_loss: 0.1107 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1502 - accuracy: 0.9892 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1308 - accuracy: 0.9946 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.9892 - val_loss: 0.1079 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1357 - accuracy: 0.9892 - val_loss: 0.1072 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1283 - accuracy: 0.9892 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1254 - accuracy: 0.9946 - val_loss: 0.1060 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1179 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1146 - accuracy: 0.9946 - val_loss: 0.1047 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1333 - accuracy: 0.9946 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9946 - val_loss: 0.1035 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1363 - accuracy: 0.9839 - val_loss: 0.1029 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1312 - accuracy: 0.9839 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1168 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1278 - accuracy: 0.9946 - val_loss: 0.1010 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1274 - accuracy: 0.9946 - val_loss: 0.1004 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1206 - accuracy: 0.9946 - val_loss: 0.0998 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1342 - accuracy: 0.9839 - val_loss: 0.0993 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1186 - accuracy: 0.9892 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1168 - accuracy: 0.9892 - val_loss: 0.0978 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1253 - accuracy: 0.9892 - val_loss: 0.0973 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1185 - accuracy: 0.9946 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1193 - accuracy: 0.9946 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1335 - accuracy: 0.9892 - val_loss: 0.0952 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1302 - accuracy: 0.9946 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1178 - accuracy: 0.9892 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1621 - accuracy: 0.9785 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1168 - accuracy: 0.9946 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1416 - accuracy: 0.9839 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1201 - accuracy: 0.9892 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1033 - accuracy: 0.9946 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1104 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1114 - accuracy: 0.9892 - val_loss: 0.0881 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0991 - accuracy: 0.9946 - val_loss: 0.0876 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1096 - accuracy: 0.9946 - val_loss: 0.0872 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1050 - accuracy: 0.9946 - val_loss: 0.0868 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1012 - accuracy: 0.9892 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0986 - accuracy: 0.9946 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0994 - accuracy: 0.9946 - val_loss: 0.0818 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1064 - accuracy: 0.9892 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.9946 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0943 - accuracy: 0.9892 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0879 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1479 - accuracy: 0.9892 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0909 - accuracy: 0.9892 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1052 - accuracy: 0.9892 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0866 - accuracy: 0.9946 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0920 - accuracy: 0.9946 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0913 - accuracy: 0.9892 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0840 - accuracy: 0.9946 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0828 - accuracy: 0.9946 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0902 - accuracy: 0.9892 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0860 - accuracy: 0.9946 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0843 - accuracy: 0.9892 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0828 - accuracy: 0.9946 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9892 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9892 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0802 - accuracy: 0.9946 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0736 - accuracy: 0.9946 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.9946 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0729 - accuracy: 0.9946 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9839 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.9946 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0687 - accuracy: 0.9946 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0710 - accuracy: 0.9892 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0699 - accuracy: 0.9946 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0637 - accuracy: 0.9946 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9946 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0794 - accuracy: 0.9946 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9946 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 0.9946 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0687 - accuracy: 0.9946 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9892 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.9946 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9946 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0599 - accuracy: 0.9946 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9892 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9946 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0571 - accuracy: 0.9946 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0622 - accuracy: 0.9946 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0582 - accuracy: 0.9892 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9946 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0541 - accuracy: 0.9946 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 0.9946 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 0.9946 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9946 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9946 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9946 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9946 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0533 - accuracy: 0.9892 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9946 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0650 - accuracy: 0.9946 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9946 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.9946 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 0.9946 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0446 - accuracy: 0.9946 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0437 - accuracy: 0.9946 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9946 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9946 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0487 - accuracy: 0.9892 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 0.9946 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9946 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0429 - accuracy: 0.9946 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0440 - accuracy: 0.9946 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9946 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9946 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0385 - accuracy: 0.9946 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0369 - accuracy: 0.9946 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.9946 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9946 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0459 - accuracy: 0.9946 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9946 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0448 - accuracy: 0.9892 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 1.0000\n",
      "Evaluation Result: [0.028002867475152016, 1.0]\n",
      "NeuralNetwork model saved to saved_models\\NeuralNetwork.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ann' object has no attribute 'encoders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m model\u001b[38;5;241m.\u001b[39mfit_models()\n\u001b[0;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate_models()\n\u001b[1;32m---> 83\u001b[0m model\u001b[38;5;241m.\u001b[39msave_model()\n",
      "Cell \u001b[1;32mIn[72], line 72\u001b[0m, in \u001b[0;36mann.save_model\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeuralNetwork model saved to\u001b[39m\u001b[38;5;124m'\u001b[39m, model_path)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Save encoders using joblib\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, encoder \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# Assuming self.encoders stores your encoders\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     encoder_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_encoder.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m     joblib\u001b[38;5;241m.\u001b[39mdump(encoder, encoder_file)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ann' object has no attribute 'encoders'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, callbacks\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "class ann:\n",
    "    def __init__(self, data, target, input_shape):\n",
    "        x = data.drop(target, axis=1)\n",
    "        y = data[target]\n",
    "\n",
    "        # Feature Scaling\n",
    "        x = (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.model = keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', input_shape=(self.input_shape,),\n",
    "                         kernel_regularizer=regularizers.l2(0.001)), # L2 Regularization\n",
    "            layers.Dropout(0.5), # Dropout\n",
    "            layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(3, activation='softmax') \n",
    "        ])\n",
    "\n",
    "        self.metrics = {}\n",
    "        self.early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "        self.checkpoint = callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "\n",
    "    def compile_neural_network(self):\n",
    "        self.model.compile(optimizer='adam', \n",
    "                           loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    def fit_models(self):\n",
    "        history = self.model.fit(self.x_train, self.y_train, epochs=1000, \n",
    "                                 validation_split=0.2, callbacks=[self.early_stopping, self.checkpoint])\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Val'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate_models(self):\n",
    "        self.model.load_weights('best_model.h5')\n",
    "        result = self.model.evaluate(self.x_test, self.y_test)\n",
    "        print(f'Evaluation Result: {result}')\n",
    "\n",
    "    def save_model(self, directory='saved_models'):\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Save the neural network model\n",
    "        model_path = os.path.join(directory, 'NeuralNetwork.h5')\n",
    "        self.model.save(model_path)\n",
    "        print('NeuralNetwork model saved to', model_path)\n",
    "\n",
    "\n",
    "        # Save encoders using joblib\n",
    "        for col, encoder in self.encoders.items():  # Assuming self.encoders stores your encoders\n",
    "            encoder_file = os.path.join(directory, f'{col}_encoder.pkl')\n",
    "            joblib.dump(encoder, encoder_file)\n",
    "            print(f'Encoder for {col} saved to {encoder_file}')\n",
    "\n",
    "\n",
    "\n",
    "model = ann(penguins, 'species', 6)\n",
    "model.compile_neural_network()\n",
    "model.fit_models()\n",
    "model.evaluate_models()\n",
    "model.save_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
